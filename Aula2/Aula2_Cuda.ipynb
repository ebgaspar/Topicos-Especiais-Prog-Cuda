{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula2_Cuda",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZvP3btPeAqT",
        "outputId": "0cef8021-a7b2-4890-889d-50742e524b35"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjFHfyqOeZ_d"
      },
      "source": [
        "##Configuração do Ambiente no Colab\n",
        "\n",
        "Artigo inicial  \n",
        "https://harshityadav95.medium.com/how-to-run-cuda-c-or-c-on-google-colab-or-azure-notebook-ea75a23a5962\n",
        "\n",
        "Link da configuração:  \n",
        "https://gist.github.com/harshityadav95/e56c525dcc14eec0d4f64eac67ad5102  \n",
        "\n",
        "Antes de cada bloco de execução é necessário colocar **%%cu**!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgYiLEL9eJm0",
        "outputId": "1ea871f4-ab3f-4084-871a-77f8e9575ebb"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-jjd7jf43\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-jjd7jf43\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4305 sha256=1ccb90fc803c0c2407cfd60f46f4667f560659c91113aca41c73565f7e559937\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-31o0mmyy/wheels/c5/2b/c0/87008e795a14bbcdfc7c846a00d06981916331eb980b6c8bdf\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDflMvTYfYA8"
      },
      "source": [
        "## 1º Programa Cuda  \n",
        "O programa apenas imprime o Id de cada thread.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUWHT7eKeRDu",
        "outputId": "4f0c6893-359a-4688-b5dc-1e42a74dd57e"
      },
      "source": [
        "%%cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void meu_kernel( void )\n",
        "{\n",
        "\tprintf( \"Meu ID: %d\\n\" , threadIdx.x );\n",
        "}\n",
        "\n",
        "int main( )\n",
        "{\n",
        "\t// Define a variável de captura de erros\n",
        "\tcudaError_t cudaStatus;\n",
        "\n",
        "\t// Informa o device a ser usado caso exista mais de 1\n",
        "\tcudaStatus = cudaSetDevice( 0 );\n",
        "\n",
        "\t// Testa a função cudaSetDevice retornou erro\n",
        "\tif ( cudaStatus != cudaSuccess )\n",
        "\t{\n",
        "\t\tfprintf( stderr , \"cudaSetDevice falhou!  Existe dispositivo com suporte a CUDA instalado?\" );\n",
        "    fprintf( stderr , \"\\n\\n%s\", cudaGetErrorString( cudaStatus ) );\n",
        "\t\tgoto Error;\n",
        "\t}\n",
        "\n",
        "\tfprintf( stdout , \"Inicio\\n\" );\n",
        "\n",
        "\tmeu_kernel <<< 2 , 5 >>> ( );\n",
        "\n",
        "\t// Captura o último erro ocorrido\n",
        "\tcudaStatus = cudaGetLastError( );\n",
        "\tif ( cudaStatus != cudaSuccess )\n",
        "\t{\n",
        "\t\tfprintf( stderr , \"meu_kernel falhou: %s\\n\" , cudaGetErrorString( cudaStatus ) );\n",
        "\t\tgoto Error;\n",
        "\t}\n",
        "\n",
        "\t// Sincroniza a execução do kernel com a CPU\n",
        "\tcudaStatus = cudaDeviceSynchronize( );\n",
        "\tif ( cudaStatus != cudaSuccess )\n",
        "\t{\n",
        "\t\tfprintf( stderr , \"cudaDeviceSynchronize retornou erro %d após lançamento do kernel!\\n\" , cudaStatus );\n",
        "\t\tgoto Error;\n",
        "\t}\n",
        "\tfprintf( stdout , \"Fim\\n\" );\n",
        "Error:\n",
        "\t// Executa a limpeza GPU\n",
        "\tcudaStatus = cudaDeviceReset( );\n",
        "\tif ( cudaStatus != cudaSuccess )\n",
        "\t{\n",
        "\t\tfprintf( stderr , \"cudaDeviceReset falhou!\" );\n",
        "\t\treturn 1;\n",
        "\t}\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inicio\n",
            "Meu ID: 0\n",
            "Meu ID: 1\n",
            "Meu ID: 2\n",
            "Meu ID: 3\n",
            "Meu ID: 4\n",
            "Meu ID: 0\n",
            "Meu ID: 1\n",
            "Meu ID: 2\n",
            "Meu ID: 3\n",
            "Meu ID: 4\n",
            "Fim\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxH47NwsgciY"
      },
      "source": [
        "## Detectar e inspecionar dispositivos compatíves com Cuda  \n",
        "É possível inspecionar o sistema e obter informações sobre o hardware instalado.  \n",
        "Isso auxiliará na criação e configuração do kernel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNttsMTOgctk",
        "outputId": "ac652e5b-4933-4a7c-8c52-8d3c2846f058"
      },
      "source": [
        "%%cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "int main( int argc , char** argv )\n",
        "{\n",
        "\n",
        "\tfprintf( stdout , \" CUDA Device Query\\n\" );\n",
        "\n",
        "\tint deviceCount = 0;\n",
        " \n",
        "  // Testa se existem dispositivos compatíveis com Cuda\n",
        "\tcudaError_t cudaStatus = cudaGetDeviceCount( &deviceCount );\n",
        "\n",
        "\tif ( cudaStatus != cudaSuccess )\n",
        "\t{\n",
        "\t\tfprintf( stderr , \"cudaGetDeviceCount retornou código: %d\\n -> %s\\n\" , cudaStatus , cudaGetErrorString( cudaStatus ) );\n",
        "\t\texit( 1 );\n",
        "\t}\n",
        "\n",
        "\t// A função retorna 0 caso não exista hardware que suporte cuda.\n",
        "\tif ( deviceCount == 0 )\n",
        "\t{\n",
        "\t\tfprintf( stdout , \"Não há dispositivo compatível com CUDA\\n\" );\n",
        "\t}\n",
        "\telse\n",
        "\t{\n",
        "\t\tfprintf( stdout , \"Detectado %d dispositivo(s) CUDA\\n\" , deviceCount );\n",
        "\t}\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " CUDA Device Query\n",
            "Detectado 1 dispositivo(s) CUDA\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2QSz4frlT_V",
        "outputId": "ef084722-e241-4c44-b93d-fa9da69e279e"
      },
      "source": [
        "%%cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "int main( int argc , char** argv )\n",
        "{\n",
        "\n",
        "\tfprintf( stdout , \"CUDA Device Query\\n\" );\n",
        "\n",
        "\tint deviceCount = 0;\n",
        " \n",
        "  // Testa se existem dispositivos compatíveis com Cuda\n",
        "\tcudaError_t cudaStatus = cudaGetDeviceCount( &deviceCount );\n",
        "\n",
        "\tif ( cudaStatus != cudaSuccess )\n",
        "\t{\n",
        "\t\tfprintf( stderr , \"cudaGetDeviceCount retornou código: %d\\n -> %s\\n\" , cudaStatus , cudaGetErrorString( cudaStatus ) );\n",
        "\t\texit( 1 );\n",
        "\t}\n",
        "\n",
        "\t// A função retorna 0 caso não exista hardware que suporte cuda.\n",
        "\tif ( deviceCount == 0 )\n",
        "\t{\n",
        "\t\tfprintf( stdout , \"Não há dispositivo compatível com CUDA\\n\" );\n",
        "\t}\n",
        "\telse\n",
        "\t{\n",
        "\t\tfprintf( stdout , \"Detectado %d dispositivo(s) CUDA\\n\" , deviceCount );\n",
        "\t}\n",
        " \n",
        "\tint dev , driverVersion = 0 , runtimeVersion = 0;\n",
        "\n",
        "\tfor ( dev = 0; dev < deviceCount; ++dev )\n",
        "\t{\n",
        "\t\tcudaSetDevice( dev );\n",
        "\t\tcudaDeviceProp deviceProp;\n",
        "\t\tcudaGetDeviceProperties( &deviceProp , dev );\n",
        "\n",
        "\t\tfprintf( stdout, \"\\nDevice %d: \\\"%s\\\"\\n\" , dev , deviceProp.name );\n",
        "  \n",
        " \t\tcudaDriverGetVersion( &driverVersion );\n",
        "\t\tcudaRuntimeGetVersion( &runtimeVersion );\n",
        "\t\tcudaDriverGetVersion( &driverVersion );\n",
        "\t\tcudaRuntimeGetVersion( &runtimeVersion );\n",
        "\t\tfprintf( stdout, \"CUDA Driver Version / Runtime Version %d.%d / %d.%d\\n\" , driverVersion / 1000 , ( driverVersion % 100 ) / 10 , runtimeVersion / 1000 , ( runtimeVersion % 100 ) / 10 );\n",
        "\t\tfprintf( stdout, \"CUDA Capability Major/Minor version number: %d.%d\\n\" , deviceProp.major , deviceProp.minor );\n",
        "    fprintf( stdout, \"QTD Multiprocessors: %d \\n\" , deviceProp.multiProcessorCount );\n",
        "    fprintf( stdout, \"Total constant memory:%zu bytes\\n\", deviceProp.totalConstMem );\n",
        "    fprintf( stdout, \"Total shared memory per block:%zu bytes\\n\", deviceProp.sharedMemPerBlock );\n",
        "    fprintf( stdout, \"Shared memory per multiprocessor:%zu bytes\\n\", deviceProp.sharedMemPerMultiprocessor );\n",
        "    fprintf( stdout, \"Number of registers available per block:%d\\n\", deviceProp.regsPerBlock );\n",
        "  }\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Device Query\n",
            "Detectado 1 dispositivo(s) CUDA\n",
            "\n",
            "Device 0: \"Tesla T4\"\n",
            "CUDA Driver Version / Runtime Version 11.2 / 11.0\n",
            "CUDA Capability Major/Minor version number: 7.5\n",
            "QTD Multiprocessors: 40 \n",
            "Total constant memory:65536 bytes\n",
            "Total shared memory per block:49152 bytes\n",
            "Shared memory per multiprocessor:65536 bytes\n",
            "Number of registers available per block:65536\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5Gsp7TswMsa"
      },
      "source": [
        "Outras informações contidas na estrutura cudaDeviceProp:\n",
        "\n",
        "- deviceProp.warpSize\n",
        "- deviceProp.maxThreadsPerMultiProcessor\n",
        "- deviceProp.maxThreadsPerBlock\n",
        "- deviceProp.maxThreadsDim\n",
        "- deviceProp.maxGridSize\n",
        "- deviceProp.memPitch\n",
        "- deviceProp.textureAlignment\n",
        "\n",
        "Link da documentação:\n",
        "https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H75aobNRxElN"
      },
      "source": [
        "## Exemplo soma de 2 vetores\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFXhamrIxDMn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa65cd8f-2f84-413e-d747-a15bbc0d4fce"
      },
      "source": [
        "%%cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void addKernel( int* c , const int* a , const int* b )\n",
        "{\n",
        "\tint i = threadIdx.x;\n",
        "\tc[ i ] = a[ i ] + b[ i ];\n",
        "}\n",
        "\n",
        "int main( )\n",
        "{\n",
        "\tconst int arraySize = 5;\n",
        "\tconst int a[ arraySize ] = { 1, 2, 3, 4, 5 };\n",
        "\tconst int b[ arraySize ] = { 10, 20, 30, 40, 50 };\n",
        "\tint c[ arraySize ] = { 0 };\n",
        "\n",
        "\tint* dev_a = 0;\n",
        "\tint* dev_b = 0;\n",
        "\tint* dev_c = 0;\n",
        "\tcudaError_t cudaStatus;\n",
        "\n",
        "\t// Alocar espaço na memória do device\n",
        "\tcudaStatus = cudaMalloc( ( void** ) &dev_c , arraySize * sizeof( int ) );\n",
        "\tif ( cudaStatus != cudaSuccess )\n",
        "\t{\n",
        "\t\tfprintf( stderr , \"cudaMalloc failed!\" );\n",
        "\t\tgoto Error;\n",
        "\t}\n",
        "\n",
        "\tcudaStatus = cudaMalloc( ( void** ) &dev_a , arraySize * sizeof( int ) );\n",
        "\tif ( cudaStatus != cudaSuccess )\n",
        "\t{\n",
        "\t\tfprintf( stderr , \"cudaMalloc failed!\" );\n",
        "\t\tgoto Error;\n",
        "\t}\n",
        "\n",
        "\tcudaStatus = cudaMalloc( ( void** ) &dev_b , arraySize * sizeof( int ) );\n",
        "\tif ( cudaStatus != cudaSuccess )\n",
        "\t{\n",
        "\t\tfprintf( stderr , \"cudaMalloc failed!\" );\n",
        "\t\tgoto Error;\n",
        "\t}\n",
        "\n",
        "\t// Copia os vetores do host para a device\n",
        "\tcudaStatus = cudaMemcpy( dev_a , a , arraySize * sizeof( int ) , cudaMemcpyHostToDevice );\n",
        "\tif ( cudaStatus != cudaSuccess )\n",
        "\t{\n",
        "\t\tfprintf( stderr , \"cudaMemcpy failed!\" );\n",
        "\t\tgoto Error;\n",
        "\t}\n",
        "\n",
        "\tcudaStatus = cudaMemcpy( dev_b , b , arraySize * sizeof( int ) , cudaMemcpyHostToDevice );\n",
        "\tif ( cudaStatus != cudaSuccess )\n",
        "\t{\n",
        "\t\tfprintf( stderr , \"cudaMemcpy failed!\" );\n",
        "\t\tgoto Error;\n",
        "\t}\n",
        "\n",
        "\t// Executar o kernel\n",
        "\taddKernel <<<1 , arraySize >> > ( dev_c , dev_a , dev_b );\n",
        "\n",
        "\t// Verificar se o kernel foi executado corretamente\n",
        "\tcudaStatus = cudaGetLastError( );\n",
        "\tif ( cudaStatus != cudaSuccess )\n",
        "\t{\n",
        "\t\tfprintf( stderr , \"addKernel launch failed: %s\\n\" , cudaGetErrorString( cudaStatus ) );\n",
        "\t\tgoto Error;\n",
        "\t}\n",
        "\n",
        "\t// Espera o kernel terminar e retorna quaisquer erros encontrados durante a execução\n",
        "\tcudaStatus = cudaDeviceSynchronize( );\n",
        "\tif ( cudaStatus != cudaSuccess )\n",
        "\t{\n",
        "\t\tfprintf( stderr , \"cudaDeviceSynchronize returned error code %d after launching addKernel!\\n\" , cudaStatus );\n",
        "\t\tgoto Error;\n",
        "\t}\n",
        "\n",
        "\t// Copia o resultado do device para a memória do host.\n",
        "\tcudaStatus = cudaMemcpy( c , dev_c , arraySize * sizeof( int ) , cudaMemcpyDeviceToHost );\n",
        "\tif ( cudaStatus != cudaSuccess )\n",
        "\t{\n",
        "\t\tfprintf( stderr , \"cudaMemcpy failed!\" );\n",
        "\t\tgoto Error;\n",
        "\t}\n",
        "\n",
        "\tprintf( \"{1,2,3,4,5} + {10,20,30,40,50} = {%d,%d,%d,%d,%d}\\n\" , c[ 0 ] , c[ 1 ] , c[ 2 ] , c[ 3 ] , c[ 4 ] );\n",
        "\n",
        "\t// Limpa a memória\n",
        "Error:\n",
        "\tcudaFree( dev_c );\n",
        "\tcudaFree( dev_a );\n",
        "\tcudaFree( dev_b );\n",
        "\n",
        "\tcudaStatus = cudaDeviceReset( );\n",
        "\tif ( cudaStatus != cudaSuccess )\n",
        "\t{\n",
        "\t\tfprintf( stderr , \"cudaDeviceReset failed!\" );\n",
        "\t\treturn 1;\n",
        "\t}\n",
        "\n",
        "\treturn 0;\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1,2,3,4,5} + {10,20,30,40,50} = {11,22,33,44,55}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}